{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import *\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = loadmat('./Dataset/TrainData1.mat')\n",
    "data1_test = loadmat('./Dataset/TestData1.mat')\n",
    "data2 = loadmat('./Dataset/TrainData2.mat')\n",
    "data2_test = loadmat('./Dataset/TestData2.mat')\n",
    "data3 = loadmat('./Dataset/TrainData3.mat')\n",
    "data3_test = loadmat('./Dataset/TestData3.mat')\n",
    "data4 = loadmat('./Dataset/TrainData4.mat')\n",
    "data4_test = loadmat('./Dataset/TestData4.mat')\n",
    "data5 = loadmat('./Dataset/TrainData5.mat')\n",
    "data5_test = loadmat('./Dataset/TestData5.mat')\n",
    "data6 = loadmat('./Dataset/TrainData6.mat')\n",
    "data6_test = loadmat('./Dataset/TestData6.mat')\n",
    "data7 = loadmat('./Dataset/TrainData7.mat')\n",
    "data7_test = loadmat('./Dataset/TestData7.mat')\n",
    "data8 = loadmat('./Dataset/TrainData8.mat')\n",
    "data8_test = loadmat('./Dataset/TestData8.mat')\n",
    "data9 = loadmat('./Dataset/TrainData9.mat')\n",
    "data9_test = loadmat('./Dataset/TestData9.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Person:\n",
    "    def __init__(self, data_mat):\n",
    "        self.data_name = list(data_mat.keys())[-1]\n",
    "        self.data = data_mat[self.data_name]\n",
    "        self.t_sampling = self.data[0,1] - self.data[0,0]\n",
    "    \n",
    "    def find_t_stimulated(self, data, test_data = False):\n",
    "        '''Finds the times when there was a stimulation and stores these times in a vector'''\n",
    "        \n",
    "        mask = data[9,:] != 0\n",
    "        t_stimulated = data[0,mask]\n",
    "        if (test_data == False):\n",
    "            t_stimulated = t_stimulated[0::4]\n",
    "        return t_stimulated\n",
    "    \n",
    "    def epoching(self, data, t_stimulated, test_data = False):\n",
    "        '''This function finds the 128 samples of each channel around the times that a stimulation happend\n",
    "        and also creates the label vector for each of these times and returns them as a tuple of (t_features, y)'''\n",
    "        \n",
    "        t_backward = 0.1\n",
    "        t_forward = 0.4\n",
    "        t_features = np.empty([len(t_stimulated), int((t_backward+t_forward)/self.t_sampling)*8])\n",
    "        y = np.empty(len(t_stimulated))\n",
    "        for t in t_stimulated:\n",
    "            index = np.where(t_stimulated == t)\n",
    "            t_min = t - t_backward\n",
    "            t_max = t + t_forward\n",
    "            mask = np.logical_and((data[0,:]<t_max),(data[0,:]>t_min))\n",
    "            data_masked = data[:, mask]\n",
    "            time_signal = data_masked[1:9,:]\n",
    "            features = np.array([time_signal[0,:]])\n",
    "            for j in range(1,8):\n",
    "                features = np.append(features, time_signal[j,:])\n",
    "            if(test_data == False):\n",
    "                y[index] = data[10, data[0,:] == t]\n",
    "            t_features[index,:] = features\n",
    "        return (t_features, y)\n",
    "    \n",
    "    def create_all_features(self, t_features):\n",
    "        '''This function calculates all possible features and returns them.'''\n",
    "        ## Time Features\n",
    "        # channel time signals\n",
    "        ch1 = t_features[:, 0:128]\n",
    "        ch2 = t_features[:, 128:256]\n",
    "        ch3 = t_features[:, 256:384]\n",
    "        ch4 = t_features[:, 384:512]\n",
    "        ch5 = t_features[:, 512:640]\n",
    "        ch6 = t_features[:, 640:768]\n",
    "        ch7 = t_features[:, 768:896]\n",
    "        ch8 = t_features[:, 896:1024]\n",
    "        ch = (ch1+ch2+ch3+ch4+ch5+ch6+ch7+ch8)/8\n",
    "        \n",
    "        length = ch.shape[0]\n",
    "        \n",
    "        ch_hist = self.create_hist_feature(ch)\n",
    "        ch1_hist = self.create_hist_feature(ch1)\n",
    "        ch2_hist = self.create_hist_feature(ch2)\n",
    "        ch3_hist = self.create_hist_feature(ch3)\n",
    "        ch4_hist = self.create_hist_feature(ch4)\n",
    "        ch5_hist = self.create_hist_feature(ch5)\n",
    "        ch6_hist = self.create_hist_feature(ch6)\n",
    "        ch7_hist = self.create_hist_feature(ch7)\n",
    "        ch8_hist = self.create_hist_feature(ch8)\n",
    "        \n",
    "        ch1_mean = np.mean(ch1, axis=1).reshape((length, 1))\n",
    "        ch2_mean = np.mean(ch2, axis=1).reshape((length, 1))\n",
    "        ch3_mean = np.mean(ch3, axis=1).reshape((length, 1))\n",
    "        ch4_mean = np.mean(ch4, axis=1).reshape((length, 1))\n",
    "        ch5_mean = np.mean(ch5, axis=1).reshape((length, 1))\n",
    "        ch6_mean = np.mean(ch6, axis=1).reshape((length, 1))\n",
    "        ch7_mean = np.mean(ch7, axis=1).reshape((length, 1))\n",
    "        ch8_mean = np.mean(ch8, axis=1).reshape((length, 1))\n",
    "        \n",
    "        ch1_var = np.var(ch1, axis=1).reshape((length, 1))\n",
    "        ch2_var = np.var(ch2, axis=1).reshape((length, 1))\n",
    "        ch3_var = np.var(ch3, axis=1).reshape((length, 1))\n",
    "        ch4_var = np.var(ch4, axis=1).reshape((length, 1))\n",
    "        ch5_var = np.var(ch5, axis=1).reshape((length, 1))\n",
    "        ch6_var = np.var(ch6, axis=1).reshape((length, 1))\n",
    "        ch7_var = np.var(ch7, axis=1).reshape((length, 1))\n",
    "        ch8_var = np.var(ch8, axis=1).reshape((length, 1))\n",
    "        \n",
    "        ch_corr = self.create_correlation_feature(ch1, ch2, ch3, ch4, ch5, ch6, ch7, ch8)\n",
    "        ch_freq = self.create_frequency_features(ch)\n",
    "        \n",
    "        feature_tuple = (ch, ch_freq , ch1_var, ch2_var, ch3_var, ch4_var,\n",
    "                         ch5_var, ch6_var, ch7_var, ch8_var, ch_hist, ch_corr)\n",
    "        all_features = np.concatenate(feature_tuple, axis=1)\n",
    "        #std = np.std(all_features, axis=0)\n",
    "        all_features = all_features\n",
    "        \n",
    "        return all_features\n",
    "    \n",
    "    def create_hist_feature(self, channel):\n",
    "        '''This function gets the channel time series and returns the histogram feature for it.'''\n",
    "        length = channel.shape[0]\n",
    "        bins = 12\n",
    "        channel_hist = np.empty((length, bins))\n",
    "        for i in range(length):\n",
    "            channel_sample = channel[i,:]\n",
    "            hists = np.histogram(channel_sample, bins=bins, range=(-60,60))[0]\n",
    "            channel_hist[i,:] = hists\n",
    "        return channel_hist\n",
    "    \n",
    "    def create_correlation_feature(self, ch1, ch2, ch3, ch4, ch5, ch6, ch7, ch8):\n",
    "        '''This function gets the channel time series and returns the correlation feature for it.'''\n",
    "        length = ch1.shape[0]\n",
    "        ch_corr_list = np.empty((length, 28))\n",
    "        for i in range(length):\n",
    "            ch1_sample = ch1[i,:]\n",
    "            ch2_sample = ch2[i,:]\n",
    "            ch3_sample = ch3[i,:]\n",
    "            ch4_sample = ch4[i,:]\n",
    "            ch5_sample = ch5[i,:]\n",
    "            ch6_sample = ch6[i,:]\n",
    "            ch7_sample = ch7[i,:]\n",
    "            ch8_sample = ch8[i,:]\n",
    "            corr = np.corrcoef([ch1_sample,ch2_sample,ch3_sample,ch4_sample,ch5_sample,ch6_sample\n",
    "                                      ,ch7_sample, ch8_sample])\n",
    "            ch_corr = np.array([corr[0,1], corr[0,2], corr[0,3], corr[0,4], corr[0,5], corr[0,6], corr[0,7],\n",
    "                                corr[1,2], corr[1,3], corr[1,4], corr[1,5], corr[1,6], corr[1,7],\n",
    "                                corr[2,3], corr[2,4], corr[2,5], corr[2,6], corr[2,7],\n",
    "                                corr[3,4], corr[3,5], corr[3,6], corr[3,7],\n",
    "                                corr[4,5], corr[4,6], corr[4,7],\n",
    "                                corr[5,6], corr[5,7],\n",
    "                                corr[6,7]])\n",
    "            ch_corr_list[i,:] = ch_corr\n",
    "        return ch_corr_list\n",
    "    \n",
    "    def create_frequency_features(self, ch):\n",
    "        '''Gets a channel time data and finds frequency features related to it.'''\n",
    "        length = ch.shape[0]\n",
    "        N = 4096\n",
    "        ch_fft = abs(np.fft.rfft(ch, N))\n",
    "        ch_fft_no_dc = np.delete(ch_fft,0,1)\n",
    "        ch_psd = ch_fft**2\n",
    "        f = np.arange(0, N/2+1) * 128/(N/2)\n",
    "        # 0.5Hz <= f < 4Hz\n",
    "        mask1 = np.logical_and(f>=0.4, f<4)\n",
    "        ch_psd1 = ch_psd[:,mask1]\n",
    "        ch_energy1 = np.sum(ch_psd1, axis=1)\n",
    "        # 4Hz <= f < 8Hz\n",
    "        mask2 = np.logical_and(f>=4, f<8)\n",
    "        ch_psd2 = ch_psd[:,mask2]\n",
    "        ch_energy2 = np.sum(ch_psd2, axis=1)\n",
    "        # 8Hz <= f < 13Hz\n",
    "        mask3 = np.logical_and(f>=8, f<13)\n",
    "        ch_psd3 = ch_psd[:,mask3]\n",
    "        ch_energy3 = np.sum(ch_psd3, axis=1)\n",
    "        # 13Hz <= f < 30Hz\n",
    "        mask4 = np.logical_and(f>=13, f<30)\n",
    "        ch_psd4 = ch_psd[:,mask4]\n",
    "        ch_energy4 = np.sum(ch_psd4, axis=1)\n",
    "        # 30Hz <= f\n",
    "        mask5 = f>=30\n",
    "        ch_psd5 = ch_psd[:,mask5]\n",
    "        ch_energy5 = np.sum(ch_psd5, axis=1)\n",
    "        \n",
    "        \n",
    "        # mean frequency\n",
    "        f_array = np.array([f]*length)\n",
    "        f_mean = np.sum(f_array * ch_fft, axis=1)/np.sum(ch_fft, axis=1)\n",
    "        \n",
    "        # 5 max frequencies\n",
    "        ind = np.argsort(-ch_fft[:,1:], axis=1)\n",
    "        f_sorted = np.take_along_axis(f_array[:,1:], ind, axis=1)\n",
    "        f_5_max = f_sorted[:,0:5]\n",
    "        \n",
    "        # appending features together\n",
    "        temp1 = np.append(ch_energy1.reshape((length, 1)), ch_energy2.reshape((length, 1)), axis=1)\n",
    "        temp2 = np.append(ch_energy3.reshape((length, 1)), ch_energy4.reshape((length, 1)), axis=1)\n",
    "        f_features = np.append(temp1, temp2, axis=1)\n",
    "        f_features = np.append(f_features, ch_energy5.reshape((length, 1)), axis=1)\n",
    "        f_features = np.append(f_features, f_mean.reshape(length, 1), axis=1)\n",
    "        f_features = np.append(f_features, f_5_max, axis=1)\n",
    "        \n",
    "        return f_features\n",
    "    \n",
    "    def return_features(self, data, test_data=False):\n",
    "        '''Gets a dataset as its input and creates all possible features using this dataset in order to be used later\n",
    "        and returns these features as its output.'''\n",
    "        \n",
    "        print(\"Creating all possible features...\\n\")\n",
    "        t_stimulated = self.find_t_stimulated(data, test_data)\n",
    "        t_features, y = self.epoching(data, t_stimulated, test_data)\n",
    "        all_features = self.create_all_features(t_features)\n",
    "        if (test_data):\n",
    "            out = all_features\n",
    "        else:\n",
    "            out = (all_features, y)\n",
    "        return out\n",
    "    \n",
    "    def fisher_score_index(self, X_train, y_train):\n",
    "        '''Finds the index of fisher score (column indexes) using X_train and y_train which are the features and their\n",
    "        labels.'''\n",
    "        mask1 = (y_train==0)\n",
    "        mask2 = (y_train==1)\n",
    "\n",
    "        X1_train = X_train[mask1,:]\n",
    "        X2_train = X_train[mask2,:]\n",
    "        n1 = X1_train.shape[0]\n",
    "        n2 = X2_train.shape[0]\n",
    "\n",
    "        u0 = np.mean(X_train, axis=0)\n",
    "        u1 = np.mean(X1_train, axis=0)\n",
    "        u2 = np.mean(X2_train, axis=0)\n",
    "        var1 = np.var(X1_train, axis=0)\n",
    "        var2 = np.var(X2_train, axis=0)\n",
    "    \n",
    "        fisher_score = np.divide((n1 * (u1 - u0)**2 + n2 * (u2 - u0)**2),(n1*var1 + n2*var2))\n",
    "\n",
    "        ind = np.argsort(-fisher_score)\n",
    "        return ind\n",
    "    \n",
    "    def cross_validation(self, X, y, model, feature_num, n_splits, metric=\"roc_auc\"):\n",
    "        kf = KFold(n_splits = n_splits)\n",
    "        score_list = np.array([])\n",
    "        X = X[:, 0:feature_num]\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            score = self.scorer(model, X_train, y_train, X_test, y_test, metric)\n",
    "            score_list = np.append(score_list, score)\n",
    "        score = np.mean(score_list)\n",
    "        return score, score_list\n",
    "    \n",
    "    def scorer(self, model, X_train, y_train, X_test, y_test, metric, return_conf_matrix=False):\n",
    "        '''Finds either roc auc or accuracy of model on a given train and test dataset and returns the calculated\n",
    "        score.'''\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        if metric == \"roc_auc\":\n",
    "            score = roc_auc_score(y_test, y_pred)\n",
    "        elif metric == \"accuracy\":\n",
    "            score = balanced_accuracy_score(y_test, y_pred)\n",
    "        if(return_conf_matrix):\n",
    "            return (score, confusion_matrix(y_test, y_pred))\n",
    "        else:\n",
    "            return score\n",
    "        \n",
    "    def find_best_model(self, X, y):\n",
    "        '''Finds the best model for a given dataset using cross-validation and fisher-score, then returns the \n",
    "        shuffled, splited and sorted dataset, best model, best number of features and finally the priority of \n",
    "        the features based on their fisher-score.'''\n",
    "        X_train_all, X_test_all, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        fisher_ind = self.fisher_score_index(X_train_all, y_train)\n",
    "        X_train = X_train_all[:, fisher_ind]\n",
    "        X_test = X_test_all[:, fisher_ind]\n",
    "        models = self.model_generator()\n",
    "        feature_nums = [10, 20, 40, 70, 100]\n",
    "        scores_array = np.empty((len(models), len(feature_nums)))\n",
    "        \n",
    "        for i in range(len(models)):\n",
    "            model = models[i]\n",
    "            for j in range(len(feature_nums)):\n",
    "                progress = i/len(models)*100 + j/len(feature_nums) *100/len(models)\n",
    "                progress_str = \"{:.2f}\".format(progress)\n",
    "                print(\"Cross-Validation in progress:\", progress_str,\"%\")\n",
    "                feature_num = feature_nums[j]\n",
    "                score, score_list = self.cross_validation(X_train, y_train, model, feature_num, 6)\n",
    "                scores_array[i,j] = score\n",
    "        print(\"Cross-Validation is completed!\\n\")\n",
    "        \n",
    "        indices = np.unravel_index(np.argmax(scores_array, axis=None), scores_array.shape) \n",
    "        best_model = models[indices[0]]\n",
    "        best_feature_num = feature_nums[indices[1]]\n",
    "        return X_train, X_test, y_train, y_test, best_model, best_feature_num, fisher_ind\n",
    "        \n",
    "    def fit(self):\n",
    "        '''Simply creates the best model for a person and saves the model, the number of features which should be\n",
    "        used in the model and finally the indexing for sorting features based on their fisher score.'''\n",
    "        X, y = self.return_features(self.data)\n",
    "        print(\"\\nFinding the best model is started...\")\n",
    "        \n",
    "        X_train, X_test, y_train, y_test, model, feature_num, fisher_ind = self.find_best_model(X, y)\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        print(\"The best model is:\", model,\" with\", feature_num,\"features\")\n",
    "        print(\"The accuracy of the best model is:\", \"{:.2f}%\".format(acc*100))\n",
    "        print(\"The roc_auc of the best model is:\", \"{:.2f}%\".format(roc_auc*100))\n",
    "        print(\"The confusion matrix of the best model is:\\n\", conf_matrix)\n",
    "        \n",
    "        X_all = (X[:, fisher_ind])[:, 0:feature_num]\n",
    "        model.fit(X_all, y)\n",
    "        self.model = model\n",
    "        self.X_train = X_all\n",
    "        self.y_train = y\n",
    "        self.feature_num = feature_num\n",
    "        self.fisher_ind = fisher_ind\n",
    "        filename = './models/'+ self.data_name + '_Model.sav'\n",
    "        pickle.dump(model, open(filename, 'wb'))\n",
    "        \n",
    "        print(\"Test confusion matrix:\\n\", confusion_matrix(y, model.predict(X_all)))\n",
    "        \n",
    "    def load_test_data(self, data_mat):\n",
    "        '''Gets a dataset as its input and findes the features(sorted and selected based on the fisher score \n",
    "        calculated in create_best_model function) for this dataset and also the stimulation times for this dataset.'''\n",
    "        print(\"\\nLoading the test data is started...\")\n",
    "        data_name = list(data_mat.keys())[-1]\n",
    "        data = data_mat[data_name]\n",
    "        t_stimulated = self.find_t_stimulated(data, test_data=True)\n",
    "        chars_array = []\n",
    "        for t in t_stimulated:\n",
    "            index = np.where(t_stimulated == t)\n",
    "            char = data[9,np.where(data[0,:] == t)][0,0]\n",
    "            chars_array.append(char)\n",
    "        X = self.return_features(data, test_data = True)\n",
    "        X_sorted = X[:, self.fisher_ind]\n",
    "        X_test = X_sorted[:, 0:self.feature_num]\n",
    "        self.X_test = X_test\n",
    "        self.t_stimulated_test = t_stimulated\n",
    "        self.chars_array = np.array(chars_array)\n",
    "        \n",
    "    def find_test_word(self):\n",
    "        model = self.model\n",
    "        y_pred = model.predict(self.X_test)\n",
    "        mask = y_pred == 1\n",
    "        chars_array = self.chars_array\n",
    "        chars = chars_array[mask]\n",
    "        print(\"Ones founded:\", chars.shape[0])\n",
    "        \n",
    "        max_char = max(chars)\n",
    "        \n",
    "        if(max_char > 12):\n",
    "            word = self.display_type1(chars)\n",
    "            print(\"Single Character Display.\")\n",
    "        else:\n",
    "            word = self.display_type2(chars_array, mask)\n",
    "            print(\"Row-Column Display.\")\n",
    "            \n",
    "        print(\"The final word is:\\n\", word)\n",
    "        \n",
    "    def display_type1(self, chars):\n",
    "        '''Finds the intended word in the Single Character display type.'''\n",
    "        char_dict = {1:'A', 2:'B', 3:'C', 4:'D', 5:'E', 6:'F', 7:'G', 8:'H', 9:'I', 10:'J', 11:'K', 12:'L', 13:'M',\n",
    "                     14:'N', 15:'O', 16:'P', 17:'Q', 18:'R', 19:'S', 20:'T', 21:'U', 22:'V', 23:'W', 24:'X', 25:'Y',\n",
    "                     26:'Z', 27:'0', 28:'1', 29:'2', 30:'3', 31:'4', 32:'5', 33:'6', 34:'7', 35:'8', 36:'9'}\n",
    "        \n",
    "        step = int(chars.shape[0]/5)\n",
    "        char1 = chars[0:step].astype(int)\n",
    "        char2 = chars[step:2*step].astype(int)\n",
    "        char3 = chars[2*step:3*step].astype(int)\n",
    "        char4 = chars[3*step:4*step].astype(int)\n",
    "        char5 = chars[4*step:].astype(int)\n",
    "        \n",
    "        i1 = np.bincount(char1).argmax()\n",
    "        i2 = np.bincount(char2).argmax()\n",
    "        i3 = np.bincount(char3).argmax()\n",
    "        i4 = np.bincount(char4).argmax()\n",
    "        i5 = np.bincount(char5).argmax()\n",
    "        \n",
    "        word = char_dict[i1] + char_dict[i2] + char_dict[i3] + char_dict[i4] + char_dict[i5]\n",
    "        return word\n",
    "    \n",
    "    def display_type2(self, chars_array, mask):\n",
    "        '''Finds the intended word in the Row-Column display type.'''\n",
    "        chars_array = chars_array.astype('int')\n",
    "        char_dict = [['A', 'B', 'C', 'D', 'E', 'F'],\n",
    "                     ['G', 'H', 'I', 'J', 'K', 'L'],\n",
    "                     ['M', 'N', 'O', 'P', 'Q', 'R'],\n",
    "                     ['S', 'T', 'U', 'V', 'W', 'X'],\n",
    "                     ['Y', 'Z', '0', '1', '2', '3'],\n",
    "                     ['4', '5', '6', '7', '8', '9']]\n",
    "\n",
    "        chars = chars_array[mask].astype(int)\n",
    "        step = int(chars.shape[0]/5)\n",
    "        chars1 = chars[0:step]\n",
    "        chars2 = chars[step:2*step]\n",
    "        chars3 = chars[2*step:3*step]\n",
    "        chars4 = chars[3*step:4*step]\n",
    "        chars5 = chars[4*step:]\n",
    "        \n",
    "        chars1_row = chars1[chars1<=6]\n",
    "        chars2_row = chars2[chars2<=6]\n",
    "        chars3_row = chars3[chars3<=6]\n",
    "        chars4_row = chars4[chars4<=6]\n",
    "        chars5_row = chars5[chars5<=6]\n",
    "        \n",
    "        chars1_col = chars1[chars1>6]\n",
    "        chars2_col = chars2[chars2>6]\n",
    "        chars3_col = chars3[chars3>6]\n",
    "        chars4_col = chars4[chars4>6]\n",
    "        chars5_col = chars5[chars5>6]\n",
    "        \n",
    "        row1 = self.most_frequent(chars1_row)-1\n",
    "        row2 = self.most_frequent(chars2_row)-1\n",
    "        row3 = self.most_frequent(chars3_row)-1\n",
    "        row4 = self.most_frequent(chars4_row)-1\n",
    "        row5 = self.most_frequent(chars5_row)-1\n",
    "        \n",
    "        col1 = self.most_frequent(chars1_col)-7\n",
    "        col2 = self.most_frequent(chars2_col)-7\n",
    "        col3 = self.most_frequent(chars3_col)-7\n",
    "        col4 = self.most_frequent(chars4_col)-7\n",
    "        col5 = self.most_frequent(chars5_col)-7\n",
    "        \n",
    "        char1 = char_dict[row1][col1]\n",
    "        char2 = char_dict[row2][col2]\n",
    "        char3 = char_dict[row3][col3]\n",
    "        char4 = char_dict[row4][col4]\n",
    "        char5 = char_dict[row5][col5]\n",
    "        \n",
    "        word = char1+char2+char3+char4+char5\n",
    "        return word\n",
    "        \n",
    "    def model_generator(self):\n",
    "        '''This method just creates an array of different models and it was written like this just for the sake of \n",
    "        the order and the beauty of the code.'''\n",
    "        return [LogisticRegression(class_weight={0:1, 1:35}, max_iter=10000),\n",
    "                LinearDiscriminantAnalysis(),\n",
    "                LinearDiscriminantAnalysis(priors=[0.5, 0.5]),\n",
    "                RandomForestClassifier(n_estimators = 5, max_depth = 4, class_weight='balanced_subsample'),\n",
    "                RandomForestClassifier(n_estimators = 7, max_depth = 4, class_weight='balanced_subsample'),\n",
    "                RandomForestClassifier(n_estimators = 9, max_depth = 4, class_weight='balanced_subsample'),\n",
    "                RandomForestClassifier(n_estimators = 5, max_depth = 6, class_weight='balanced_subsample'),\n",
    "                RandomForestClassifier(n_estimators = 7, max_depth = 6, class_weight='balanced_subsample'),\n",
    "                RandomForestClassifier(n_estimators = 9, max_depth = 6, class_weight='balanced_subsample'),\n",
    "                RandomForestClassifier(n_estimators = 5, max_depth = 8, class_weight='balanced_subsample'),\n",
    "                RandomForestClassifier(n_estimators = 7, max_depth = 8, class_weight='balanced_subsample'),\n",
    "                RandomForestClassifier(n_estimators = 9, max_depth = 8, class_weight='balanced_subsample'),\n",
    "                #QuadraticDiscriminantAnalysis(priors = [0.5, 0.5])\n",
    "                #LogisticRegression(class_weight={0:1, 1:35}, max_iter=10000)\n",
    "                #LogisticRegression(class_weight={0:1, 1:100}, max_iter=10000)\n",
    "                ]\n",
    "    \n",
    "    def most_frequent(self, List):\n",
    "        \n",
    "        return max(set(List), key = list(List).count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Person 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating all possible features...\n",
      "\n",
      "\n",
      "Finding the best model is started...\n",
      "Cross-Validation in progress: 0.00 %\n",
      "Cross-Validation in progress: 1.67 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-d3fd1197718e>:210: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fisher_score = np.divide((n1 * (u1 - u0)**2 + n2 * (u2 - u0)**2),(n1*var1 + n2*var2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation in progress: 3.33 %\n",
      "Cross-Validation in progress: 5.00 %\n",
      "Cross-Validation in progress: 6.67 %\n",
      "Cross-Validation in progress: 8.33 %\n",
      "Cross-Validation in progress: 10.00 %\n",
      "Cross-Validation in progress: 11.67 %\n",
      "Cross-Validation in progress: 13.33 %\n",
      "Cross-Validation in progress: 15.00 %\n",
      "Cross-Validation in progress: 16.67 %\n",
      "Cross-Validation in progress: 18.33 %\n",
      "Cross-Validation in progress: 20.00 %\n",
      "Cross-Validation in progress: 21.67 %\n",
      "Cross-Validation in progress: 23.33 %\n",
      "Cross-Validation in progress: 25.00 %\n",
      "Cross-Validation in progress: 26.67 %\n",
      "Cross-Validation in progress: 28.33 %\n",
      "Cross-Validation in progress: 30.00 %\n",
      "Cross-Validation in progress: 31.67 %\n",
      "Cross-Validation in progress: 33.33 %\n",
      "Cross-Validation in progress: 35.00 %\n",
      "Cross-Validation in progress: 36.67 %\n",
      "Cross-Validation in progress: 38.33 %\n",
      "Cross-Validation in progress: 40.00 %\n",
      "Cross-Validation in progress: 41.67 %\n",
      "Cross-Validation in progress: 43.33 %\n",
      "Cross-Validation in progress: 45.00 %\n",
      "Cross-Validation in progress: 46.67 %\n",
      "Cross-Validation in progress: 48.33 %\n",
      "Cross-Validation in progress: 50.00 %\n",
      "Cross-Validation in progress: 51.67 %\n",
      "Cross-Validation in progress: 53.33 %\n",
      "Cross-Validation in progress: 55.00 %\n",
      "Cross-Validation in progress: 56.67 %\n",
      "Cross-Validation in progress: 58.33 %\n",
      "Cross-Validation in progress: 60.00 %\n",
      "Cross-Validation in progress: 61.67 %\n",
      "Cross-Validation in progress: 63.33 %\n",
      "Cross-Validation in progress: 65.00 %\n",
      "Cross-Validation in progress: 66.67 %\n",
      "Cross-Validation in progress: 68.33 %\n",
      "Cross-Validation in progress: 70.00 %\n",
      "Cross-Validation in progress: 71.67 %\n",
      "Cross-Validation in progress: 73.33 %\n",
      "Cross-Validation in progress: 75.00 %\n",
      "Cross-Validation in progress: 76.67 %\n",
      "Cross-Validation in progress: 78.33 %\n",
      "Cross-Validation in progress: 80.00 %\n",
      "Cross-Validation in progress: 81.67 %\n",
      "Cross-Validation in progress: 83.33 %\n",
      "Cross-Validation in progress: 85.00 %\n",
      "Cross-Validation in progress: 86.67 %\n",
      "Cross-Validation in progress: 88.33 %\n",
      "Cross-Validation in progress: 90.00 %\n",
      "Cross-Validation in progress: 91.67 %\n",
      "Cross-Validation in progress: 93.33 %\n",
      "Cross-Validation in progress: 95.00 %\n",
      "Cross-Validation in progress: 96.67 %\n",
      "Cross-Validation in progress: 98.33 %\n",
      "Cross-Validation is completed!\n",
      "\n",
      "The best model is: LinearDiscriminantAnalysis(priors=[0.5, 0.5])  with 10 features\n",
      "The accuracy of the best model is: 80.93%\n",
      "The roc_auc of the best model is: 56.47%\n",
      "The confusion matrix of the best model is:\n",
      " [[433  94]\n",
      " [  9   4]]\n",
      "Test confusion matrix:\n",
      " [[1620 1005]\n",
      " [  26   49]]\n"
     ]
    }
   ],
   "source": [
    "p1 = Person(data1)\n",
    "p1.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading the test data is started...\n",
      "Creating all possible features...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p1.load_test_data(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones founded: 4234\n",
      "Single Character Display.\n",
      "The final word is:\n",
      " 0WBEW\n"
     ]
    }
   ],
   "source": [
    "p1.find_test_word()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TrainData1_Model'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1.data_name + '_Model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Person 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating all possible features...\n",
      "\n",
      "\n",
      "Finding the best model is started...\n",
      "Cross-Validation in progress: 0.00 %\n",
      "Cross-Validation in progress: 1.67 %\n",
      "Cross-Validation in progress: 3.33 %\n",
      "Cross-Validation in progress: 5.00 %\n",
      "Cross-Validation in progress: 6.67 %\n",
      "Cross-Validation in progress: 8.33 %\n",
      "Cross-Validation in progress: 10.00 %\n",
      "Cross-Validation in progress: 11.67 %\n",
      "Cross-Validation in progress: 13.33 %\n",
      "Cross-Validation in progress: 15.00 %\n",
      "Cross-Validation in progress: 16.67 %\n",
      "Cross-Validation in progress: 18.33 %\n",
      "Cross-Validation in progress: 20.00 %\n",
      "Cross-Validation in progress: 21.67 %\n",
      "Cross-Validation in progress: 23.33 %\n",
      "Cross-Validation in progress: 25.00 %\n",
      "Cross-Validation in progress: 26.67 %\n",
      "Cross-Validation in progress: 28.33 %\n",
      "Cross-Validation in progress: 30.00 %\n",
      "Cross-Validation in progress: 31.67 %\n",
      "Cross-Validation in progress: 33.33 %\n",
      "Cross-Validation in progress: 35.00 %\n",
      "Cross-Validation in progress: 36.67 %\n",
      "Cross-Validation in progress: 38.33 %\n",
      "Cross-Validation in progress: 40.00 %\n",
      "Cross-Validation in progress: 41.67 %\n",
      "Cross-Validation in progress: 43.33 %\n",
      "Cross-Validation in progress: 45.00 %\n",
      "Cross-Validation in progress: 46.67 %\n",
      "Cross-Validation in progress: 48.33 %\n",
      "Cross-Validation in progress: 50.00 %\n",
      "Cross-Validation in progress: 51.67 %\n",
      "Cross-Validation in progress: 53.33 %\n",
      "Cross-Validation in progress: 55.00 %\n",
      "Cross-Validation in progress: 56.67 %\n",
      "Cross-Validation in progress: 58.33 %\n",
      "Cross-Validation in progress: 60.00 %\n",
      "Cross-Validation in progress: 61.67 %\n",
      "Cross-Validation in progress: 63.33 %\n",
      "Cross-Validation in progress: 65.00 %\n",
      "Cross-Validation in progress: 66.67 %\n",
      "Cross-Validation in progress: 68.33 %\n",
      "Cross-Validation in progress: 70.00 %\n",
      "Cross-Validation in progress: 71.67 %\n",
      "Cross-Validation in progress: 73.33 %\n",
      "Cross-Validation in progress: 75.00 %\n",
      "Cross-Validation in progress: 76.67 %\n",
      "Cross-Validation in progress: 78.33 %\n",
      "Cross-Validation in progress: 80.00 %\n",
      "Cross-Validation in progress: 81.67 %\n",
      "Cross-Validation in progress: 83.33 %\n",
      "Cross-Validation in progress: 85.00 %\n",
      "Cross-Validation in progress: 86.67 %\n",
      "Cross-Validation in progress: 88.33 %\n",
      "Cross-Validation in progress: 90.00 %\n",
      "Cross-Validation in progress: 91.67 %\n",
      "Cross-Validation in progress: 93.33 %\n",
      "Cross-Validation in progress: 95.00 %\n",
      "Cross-Validation in progress: 96.67 %\n",
      "Cross-Validation in progress: 98.33 %\n",
      "Cross-Validation is completed!\n",
      "\n",
      "The best model is: LogisticRegression(class_weight={0: 1, 1: 35}, max_iter=10000)  with 40 features\n",
      "The accuracy of the best model is: 72.04%\n",
      "The roc_auc of the best model is: 47.47%\n",
      "The confusion matrix of the best model is:\n",
      " [[385 136]\n",
      " [ 15   4]]\n",
      "Test confusion matrix:\n",
      " [[1990  635]\n",
      " [  18   57]]\n"
     ]
    }
   ],
   "source": [
    "p2 = Person(data2)\n",
    "p2.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading the test data is started...\n",
      "Creating all possible features...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p2.load_test_data(data2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones founded: 3307\n",
      "Single Character Display.\n",
      "The final word is:\n",
      " 1UKAS\n"
     ]
    }
   ],
   "source": [
    "p2.find_test_word()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(187,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2.fisher_ind.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Person 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating all possible features...\n",
      "\n",
      "\n",
      "Finding the best model is started...\n",
      "Cross-Validation in progress: 0.00 %\n",
      "Cross-Validation in progress: 1.67 %\n",
      "Cross-Validation in progress: 3.33 %\n",
      "Cross-Validation in progress: 5.00 %\n",
      "Cross-Validation in progress: 6.67 %\n",
      "Cross-Validation in progress: 8.33 %\n",
      "Cross-Validation in progress: 10.00 %\n",
      "Cross-Validation in progress: 11.67 %\n",
      "Cross-Validation in progress: 13.33 %\n",
      "Cross-Validation in progress: 15.00 %\n",
      "Cross-Validation in progress: 16.67 %\n",
      "Cross-Validation in progress: 18.33 %\n",
      "Cross-Validation in progress: 20.00 %\n",
      "Cross-Validation in progress: 21.67 %\n",
      "Cross-Validation in progress: 23.33 %\n",
      "Cross-Validation in progress: 25.00 %\n",
      "Cross-Validation in progress: 26.67 %\n",
      "Cross-Validation in progress: 28.33 %\n",
      "Cross-Validation in progress: 30.00 %\n",
      "Cross-Validation in progress: 31.67 %\n",
      "Cross-Validation in progress: 33.33 %\n",
      "Cross-Validation in progress: 35.00 %\n",
      "Cross-Validation in progress: 36.67 %\n",
      "Cross-Validation in progress: 38.33 %\n",
      "Cross-Validation in progress: 40.00 %\n",
      "Cross-Validation in progress: 41.67 %\n",
      "Cross-Validation in progress: 43.33 %\n",
      "Cross-Validation in progress: 45.00 %\n",
      "Cross-Validation in progress: 46.67 %\n",
      "Cross-Validation in progress: 48.33 %\n",
      "Cross-Validation in progress: 50.00 %\n",
      "Cross-Validation in progress: 51.67 %\n",
      "Cross-Validation in progress: 53.33 %\n",
      "Cross-Validation in progress: 55.00 %\n",
      "Cross-Validation in progress: 56.67 %\n",
      "Cross-Validation in progress: 58.33 %\n",
      "Cross-Validation in progress: 60.00 %\n",
      "Cross-Validation in progress: 61.67 %\n",
      "Cross-Validation in progress: 63.33 %\n",
      "Cross-Validation in progress: 65.00 %\n",
      "Cross-Validation in progress: 66.67 %\n",
      "Cross-Validation in progress: 68.33 %\n",
      "Cross-Validation in progress: 70.00 %\n",
      "Cross-Validation in progress: 71.67 %\n",
      "Cross-Validation in progress: 73.33 %\n",
      "Cross-Validation in progress: 75.00 %\n",
      "Cross-Validation in progress: 76.67 %\n",
      "Cross-Validation in progress: 78.33 %\n",
      "Cross-Validation in progress: 80.00 %\n",
      "Cross-Validation in progress: 81.67 %\n",
      "Cross-Validation in progress: 83.33 %\n",
      "Cross-Validation in progress: 85.00 %\n",
      "Cross-Validation in progress: 86.67 %\n",
      "Cross-Validation in progress: 88.33 %\n",
      "Cross-Validation in progress: 90.00 %\n",
      "Cross-Validation in progress: 91.67 %\n",
      "Cross-Validation in progress: 93.33 %\n",
      "Cross-Validation in progress: 95.00 %\n",
      "Cross-Validation in progress: 96.67 %\n",
      "Cross-Validation in progress: 98.33 %\n",
      "Cross-Validation is completed!\n",
      "\n",
      "The best model is: LinearDiscriminantAnalysis(priors=[0.5, 0.5])  with 20 features\n",
      "The accuracy of the best model is: 69.44%\n",
      "The roc_auc of the best model is: 65.50%\n",
      "The confusion matrix of the best model is:\n",
      " [[106  42]\n",
      " [ 13  19]]\n",
      "Test confusion matrix:\n",
      " [[478 272]\n",
      " [ 60  90]]\n"
     ]
    }
   ],
   "source": [
    "p3 = Person(data3)\n",
    "p3.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading the test data is started...\n",
      "Creating all possible features...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p3.load_test_data(data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones founded: 1374\n",
      "Row-Column Display.\n",
      "The final word is:\n",
      " 7O2AD\n"
     ]
    }
   ],
   "source": [
    "p3.find_test_word()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Person 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating all possible features...\n",
      "\n",
      "\n",
      "Finding the best model is started...\n",
      "Cross-Validation in progress: 0.00 %\n",
      "Cross-Validation in progress: 1.67 %\n",
      "Cross-Validation in progress: 3.33 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation in progress: 5.00 %\n",
      "Cross-Validation in progress: 6.67 %\n",
      "Cross-Validation in progress: 8.33 %\n",
      "Cross-Validation in progress: 10.00 %\n",
      "Cross-Validation in progress: 11.67 %\n",
      "Cross-Validation in progress: 13.33 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation in progress: 15.00 %\n",
      "Cross-Validation in progress: 16.67 %\n",
      "Cross-Validation in progress: 18.33 %\n",
      "Cross-Validation in progress: 20.00 %\n",
      "Cross-Validation in progress: 21.67 %\n",
      "Cross-Validation in progress: 23.33 %\n",
      "Cross-Validation in progress: 25.00 %\n",
      "Cross-Validation in progress: 26.67 %\n",
      "Cross-Validation in progress: 28.33 %\n",
      "Cross-Validation in progress: 30.00 %\n",
      "Cross-Validation in progress: 31.67 %\n",
      "Cross-Validation in progress: 33.33 %\n",
      "Cross-Validation in progress: 35.00 %\n",
      "Cross-Validation in progress: 36.67 %\n",
      "Cross-Validation in progress: 38.33 %\n",
      "Cross-Validation in progress: 40.00 %\n",
      "Cross-Validation in progress: 41.67 %\n",
      "Cross-Validation in progress: 43.33 %\n",
      "Cross-Validation in progress: 45.00 %\n",
      "Cross-Validation in progress: 46.67 %\n",
      "Cross-Validation in progress: 48.33 %\n",
      "Cross-Validation in progress: 50.00 %\n",
      "Cross-Validation in progress: 51.67 %\n",
      "Cross-Validation in progress: 53.33 %\n",
      "Cross-Validation in progress: 55.00 %\n",
      "Cross-Validation in progress: 56.67 %\n",
      "Cross-Validation in progress: 58.33 %\n",
      "Cross-Validation in progress: 60.00 %\n",
      "Cross-Validation in progress: 61.67 %\n",
      "Cross-Validation in progress: 63.33 %\n",
      "Cross-Validation in progress: 65.00 %\n",
      "Cross-Validation in progress: 66.67 %\n",
      "Cross-Validation in progress: 68.33 %\n",
      "Cross-Validation in progress: 70.00 %\n",
      "Cross-Validation in progress: 71.67 %\n",
      "Cross-Validation in progress: 73.33 %\n",
      "Cross-Validation in progress: 75.00 %\n",
      "Cross-Validation in progress: 76.67 %\n",
      "Cross-Validation in progress: 78.33 %\n",
      "Cross-Validation in progress: 80.00 %\n",
      "Cross-Validation in progress: 81.67 %\n",
      "Cross-Validation in progress: 83.33 %\n",
      "Cross-Validation in progress: 85.00 %\n",
      "Cross-Validation in progress: 86.67 %\n",
      "Cross-Validation in progress: 88.33 %\n",
      "Cross-Validation in progress: 90.00 %\n",
      "Cross-Validation in progress: 91.67 %\n",
      "Cross-Validation in progress: 93.33 %\n",
      "Cross-Validation in progress: 95.00 %\n",
      "Cross-Validation in progress: 96.67 %\n",
      "Cross-Validation in progress: 98.33 %\n",
      "Cross-Validation is completed!\n",
      "\n",
      "The best model is: RandomForestClassifier(class_weight='balanced_subsample', max_depth=4,\n",
      "                       n_estimators=9)  with 40 features\n",
      "The accuracy of the best model is: 73.89%\n",
      "The roc_auc of the best model is: 55.18%\n",
      "The confusion matrix of the best model is:\n",
      " [[125  26]\n",
      " [ 21   8]]\n",
      "Test confusion matrix:\n",
      " [[610 140]\n",
      " [ 43 107]]\n"
     ]
    }
   ],
   "source": [
    "p4 = Person(data4)\n",
    "p4.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading the test data is started...\n",
      "Creating all possible features...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p4.load_test_data(data4_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones founded: 946\n",
      "Row-Column Display.\n",
      "The final word is:\n",
      " 52ZCD\n"
     ]
    }
   ],
   "source": [
    "p4.find_test_word()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Person 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating all possible features...\n",
      "\n",
      "\n",
      "Finding the best model is started...\n",
      "Cross-Validation in progress: 0.00 %\n",
      "Cross-Validation in progress: 1.67 %\n",
      "Cross-Validation in progress: 3.33 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation in progress: 5.00 %\n",
      "Cross-Validation in progress: 6.67 %\n",
      "Cross-Validation in progress: 8.33 %\n",
      "Cross-Validation in progress: 10.00 %\n",
      "Cross-Validation in progress: 11.67 %\n",
      "Cross-Validation in progress: 13.33 %\n",
      "Cross-Validation in progress: 15.00 %\n",
      "Cross-Validation in progress: 16.67 %\n",
      "Cross-Validation in progress: 18.33 %\n",
      "Cross-Validation in progress: 20.00 %\n",
      "Cross-Validation in progress: 21.67 %\n",
      "Cross-Validation in progress: 23.33 %\n",
      "Cross-Validation in progress: 25.00 %\n",
      "Cross-Validation in progress: 26.67 %\n",
      "Cross-Validation in progress: 28.33 %\n",
      "Cross-Validation in progress: 30.00 %\n",
      "Cross-Validation in progress: 31.67 %\n",
      "Cross-Validation in progress: 33.33 %\n",
      "Cross-Validation in progress: 35.00 %\n",
      "Cross-Validation in progress: 36.67 %\n",
      "Cross-Validation in progress: 38.33 %\n",
      "Cross-Validation in progress: 40.00 %\n",
      "Cross-Validation in progress: 41.67 %\n",
      "Cross-Validation in progress: 43.33 %\n",
      "Cross-Validation in progress: 45.00 %\n",
      "Cross-Validation in progress: 46.67 %\n",
      "Cross-Validation in progress: 48.33 %\n",
      "Cross-Validation in progress: 50.00 %\n",
      "Cross-Validation in progress: 51.67 %\n",
      "Cross-Validation in progress: 53.33 %\n",
      "Cross-Validation in progress: 55.00 %\n",
      "Cross-Validation in progress: 56.67 %\n",
      "Cross-Validation in progress: 58.33 %\n",
      "Cross-Validation in progress: 60.00 %\n",
      "Cross-Validation in progress: 61.67 %\n",
      "Cross-Validation in progress: 63.33 %\n",
      "Cross-Validation in progress: 65.00 %\n",
      "Cross-Validation in progress: 66.67 %\n",
      "Cross-Validation in progress: 68.33 %\n",
      "Cross-Validation in progress: 70.00 %\n",
      "Cross-Validation in progress: 71.67 %\n",
      "Cross-Validation in progress: 73.33 %\n",
      "Cross-Validation in progress: 75.00 %\n",
      "Cross-Validation in progress: 76.67 %\n",
      "Cross-Validation in progress: 78.33 %\n",
      "Cross-Validation in progress: 80.00 %\n",
      "Cross-Validation in progress: 81.67 %\n",
      "Cross-Validation in progress: 83.33 %\n",
      "Cross-Validation in progress: 85.00 %\n",
      "Cross-Validation in progress: 86.67 %\n",
      "Cross-Validation in progress: 88.33 %\n",
      "Cross-Validation in progress: 90.00 %\n",
      "Cross-Validation in progress: 91.67 %\n",
      "Cross-Validation in progress: 93.33 %\n",
      "Cross-Validation in progress: 95.00 %\n",
      "Cross-Validation in progress: 96.67 %\n",
      "Cross-Validation in progress: 98.33 %\n",
      "Cross-Validation is completed!\n",
      "\n",
      "The best model is: LinearDiscriminantAnalysis(priors=[0.5, 0.5])  with 10 features\n",
      "The accuracy of the best model is: 63.33%\n",
      "The roc_auc of the best model is: 52.51%\n",
      "The confusion matrix of the best model is:\n",
      " [[104  49]\n",
      " [ 17  10]]\n",
      "Test confusion matrix:\n",
      " [[463 287]\n",
      " [ 71  79]]\n"
     ]
    }
   ],
   "source": [
    "p5 = Person(data5)\n",
    "p5.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading the test data is started...\n",
      "Creating all possible features...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p5.load_test_data(data5_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones founded: 1956\n",
      "Row-Column Display.\n",
      "The final word is:\n",
      " XAPZT\n"
     ]
    }
   ],
   "source": [
    "p5.find_test_word()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Person 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating all possible features...\n",
      "\n",
      "\n",
      "Finding the best model is started...\n",
      "Cross-Validation in progress: 0.00 %\n",
      "Cross-Validation in progress: 1.67 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-d3fd1197718e>:210: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fisher_score = np.divide((n1 * (u1 - u0)**2 + n2 * (u2 - u0)**2),(n1*var1 + n2*var2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation in progress: 3.33 %\n",
      "Cross-Validation in progress: 5.00 %\n",
      "Cross-Validation in progress: 6.67 %\n",
      "Cross-Validation in progress: 8.33 %\n",
      "Cross-Validation in progress: 10.00 %\n",
      "Cross-Validation in progress: 11.67 %\n",
      "Cross-Validation in progress: 13.33 %\n",
      "Cross-Validation in progress: 15.00 %\n",
      "Cross-Validation in progress: 16.67 %\n",
      "Cross-Validation in progress: 18.33 %\n",
      "Cross-Validation in progress: 20.00 %\n",
      "Cross-Validation in progress: 21.67 %\n",
      "Cross-Validation in progress: 23.33 %\n",
      "Cross-Validation in progress: 25.00 %\n",
      "Cross-Validation in progress: 26.67 %\n",
      "Cross-Validation in progress: 28.33 %\n",
      "Cross-Validation in progress: 30.00 %\n",
      "Cross-Validation in progress: 31.67 %\n",
      "Cross-Validation in progress: 33.33 %\n",
      "Cross-Validation in progress: 35.00 %\n",
      "Cross-Validation in progress: 36.67 %\n",
      "Cross-Validation in progress: 38.33 %\n",
      "Cross-Validation in progress: 40.00 %\n",
      "Cross-Validation in progress: 41.67 %\n",
      "Cross-Validation in progress: 43.33 %\n",
      "Cross-Validation in progress: 45.00 %\n",
      "Cross-Validation in progress: 46.67 %\n",
      "Cross-Validation in progress: 48.33 %\n",
      "Cross-Validation in progress: 50.00 %\n",
      "Cross-Validation in progress: 51.67 %\n",
      "Cross-Validation in progress: 53.33 %\n",
      "Cross-Validation in progress: 55.00 %\n",
      "Cross-Validation in progress: 56.67 %\n",
      "Cross-Validation in progress: 58.33 %\n",
      "Cross-Validation in progress: 60.00 %\n",
      "Cross-Validation in progress: 61.67 %\n",
      "Cross-Validation in progress: 63.33 %\n",
      "Cross-Validation in progress: 65.00 %\n",
      "Cross-Validation in progress: 66.67 %\n",
      "Cross-Validation in progress: 68.33 %\n",
      "Cross-Validation in progress: 70.00 %\n",
      "Cross-Validation in progress: 71.67 %\n",
      "Cross-Validation in progress: 73.33 %\n",
      "Cross-Validation in progress: 75.00 %\n",
      "Cross-Validation in progress: 76.67 %\n",
      "Cross-Validation in progress: 78.33 %\n",
      "Cross-Validation in progress: 80.00 %\n",
      "Cross-Validation in progress: 81.67 %\n",
      "Cross-Validation in progress: 83.33 %\n",
      "Cross-Validation in progress: 85.00 %\n",
      "Cross-Validation in progress: 86.67 %\n",
      "Cross-Validation in progress: 88.33 %\n",
      "Cross-Validation in progress: 90.00 %\n",
      "Cross-Validation in progress: 91.67 %\n",
      "Cross-Validation in progress: 93.33 %\n",
      "Cross-Validation in progress: 95.00 %\n",
      "Cross-Validation in progress: 96.67 %\n",
      "Cross-Validation in progress: 98.33 %\n",
      "Cross-Validation is completed!\n",
      "\n",
      "The best model is: LinearDiscriminantAnalysis(priors=[0.5, 0.5])  with 100 features\n",
      "The accuracy of the best model is: 60.00%\n",
      "The roc_auc of the best model is: 50.25%\n",
      "The confusion matrix of the best model is:\n",
      " [[96 49]\n",
      " [23 12]]\n",
      "Test confusion matrix:\n",
      " [[527 223]\n",
      " [ 40 110]]\n"
     ]
    }
   ],
   "source": [
    "p6 = Person(data6)\n",
    "p6.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading the test data is started...\n",
      "Creating all possible features...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p6.load_test_data(data6_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones founded: 1784\n",
      "Row-Column Display.\n",
      "The final word is:\n",
      " MJD4R\n"
     ]
    }
   ],
   "source": [
    "p6.find_test_word()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Person 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating all possible features...\n",
      "\n",
      "\n",
      "Finding the best model is started...\n",
      "Cross-Validation in progress: 0.00 %\n",
      "Cross-Validation in progress: 1.67 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-d3fd1197718e>:210: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fisher_score = np.divide((n1 * (u1 - u0)**2 + n2 * (u2 - u0)**2),(n1*var1 + n2*var2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation in progress: 3.33 %\n",
      "Cross-Validation in progress: 5.00 %\n",
      "Cross-Validation in progress: 6.67 %\n",
      "Cross-Validation in progress: 8.33 %\n",
      "Cross-Validation in progress: 10.00 %\n",
      "Cross-Validation in progress: 11.67 %\n",
      "Cross-Validation in progress: 13.33 %\n",
      "Cross-Validation in progress: 15.00 %\n",
      "Cross-Validation in progress: 16.67 %\n",
      "Cross-Validation in progress: 18.33 %\n",
      "Cross-Validation in progress: 20.00 %\n",
      "Cross-Validation in progress: 21.67 %\n",
      "Cross-Validation in progress: 23.33 %\n",
      "Cross-Validation in progress: 25.00 %\n",
      "Cross-Validation in progress: 26.67 %\n",
      "Cross-Validation in progress: 28.33 %\n",
      "Cross-Validation in progress: 30.00 %\n",
      "Cross-Validation in progress: 31.67 %\n",
      "Cross-Validation in progress: 33.33 %\n",
      "Cross-Validation in progress: 35.00 %\n",
      "Cross-Validation in progress: 36.67 %\n",
      "Cross-Validation in progress: 38.33 %\n",
      "Cross-Validation in progress: 40.00 %\n",
      "Cross-Validation in progress: 41.67 %\n",
      "Cross-Validation in progress: 43.33 %\n",
      "Cross-Validation in progress: 45.00 %\n",
      "Cross-Validation in progress: 46.67 %\n",
      "Cross-Validation in progress: 48.33 %\n",
      "Cross-Validation in progress: 50.00 %\n",
      "Cross-Validation in progress: 51.67 %\n",
      "Cross-Validation in progress: 53.33 %\n",
      "Cross-Validation in progress: 55.00 %\n",
      "Cross-Validation in progress: 56.67 %\n",
      "Cross-Validation in progress: 58.33 %\n",
      "Cross-Validation in progress: 60.00 %\n",
      "Cross-Validation in progress: 61.67 %\n",
      "Cross-Validation in progress: 63.33 %\n",
      "Cross-Validation in progress: 65.00 %\n",
      "Cross-Validation in progress: 66.67 %\n",
      "Cross-Validation in progress: 68.33 %\n",
      "Cross-Validation in progress: 70.00 %\n",
      "Cross-Validation in progress: 71.67 %\n",
      "Cross-Validation in progress: 73.33 %\n",
      "Cross-Validation in progress: 75.00 %\n",
      "Cross-Validation in progress: 76.67 %\n",
      "Cross-Validation in progress: 78.33 %\n",
      "Cross-Validation in progress: 80.00 %\n",
      "Cross-Validation in progress: 81.67 %\n",
      "Cross-Validation in progress: 83.33 %\n",
      "Cross-Validation in progress: 85.00 %\n",
      "Cross-Validation in progress: 86.67 %\n",
      "Cross-Validation in progress: 88.33 %\n",
      "Cross-Validation in progress: 90.00 %\n",
      "Cross-Validation in progress: 91.67 %\n",
      "Cross-Validation in progress: 93.33 %\n",
      "Cross-Validation in progress: 95.00 %\n",
      "Cross-Validation in progress: 96.67 %\n",
      "Cross-Validation in progress: 98.33 %\n",
      "Cross-Validation is completed!\n",
      "\n",
      "The best model is: RandomForestClassifier(class_weight='balanced_subsample', max_depth=4,\n",
      "                       n_estimators=9)  with 20 features\n",
      "The accuracy of the best model is: 70.56%\n",
      "The roc_auc of the best model is: 48.04%\n",
      "The confusion matrix of the best model is:\n",
      " [[124  16]\n",
      " [ 37   3]]\n",
      "Test confusion matrix:\n",
      " [[576 174]\n",
      " [ 51  99]]\n"
     ]
    }
   ],
   "source": [
    "p7 = Person(data7)\n",
    "p7.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading the test data is started...\n",
      "Creating all possible features...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p7.load_test_data(data7_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones founded: 984\n",
      "Row-Column Display.\n",
      "The final word is:\n",
      " PXLMU\n"
     ]
    }
   ],
   "source": [
    "p7.find_test_word()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Person 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating all possible features...\n",
      "\n",
      "\n",
      "Finding the best model is started...\n",
      "Cross-Validation in progress: 0.00 %\n",
      "Cross-Validation in progress: 1.67 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-d3fd1197718e>:210: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fisher_score = np.divide((n1 * (u1 - u0)**2 + n2 * (u2 - u0)**2),(n1*var1 + n2*var2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation in progress: 3.33 %\n",
      "Cross-Validation in progress: 5.00 %\n",
      "Cross-Validation in progress: 6.67 %\n",
      "Cross-Validation in progress: 8.33 %\n",
      "Cross-Validation in progress: 10.00 %\n",
      "Cross-Validation in progress: 11.67 %\n",
      "Cross-Validation in progress: 13.33 %\n",
      "Cross-Validation in progress: 15.00 %\n",
      "Cross-Validation in progress: 16.67 %\n",
      "Cross-Validation in progress: 18.33 %\n",
      "Cross-Validation in progress: 20.00 %\n",
      "Cross-Validation in progress: 21.67 %\n",
      "Cross-Validation in progress: 23.33 %\n",
      "Cross-Validation in progress: 25.00 %\n",
      "Cross-Validation in progress: 26.67 %\n",
      "Cross-Validation in progress: 28.33 %\n",
      "Cross-Validation in progress: 30.00 %\n",
      "Cross-Validation in progress: 31.67 %\n",
      "Cross-Validation in progress: 33.33 %\n",
      "Cross-Validation in progress: 35.00 %\n",
      "Cross-Validation in progress: 36.67 %\n",
      "Cross-Validation in progress: 38.33 %\n",
      "Cross-Validation in progress: 40.00 %\n",
      "Cross-Validation in progress: 41.67 %\n",
      "Cross-Validation in progress: 43.33 %\n",
      "Cross-Validation in progress: 45.00 %\n",
      "Cross-Validation in progress: 46.67 %\n",
      "Cross-Validation in progress: 48.33 %\n",
      "Cross-Validation in progress: 50.00 %\n",
      "Cross-Validation in progress: 51.67 %\n",
      "Cross-Validation in progress: 53.33 %\n",
      "Cross-Validation in progress: 55.00 %\n",
      "Cross-Validation in progress: 56.67 %\n",
      "Cross-Validation in progress: 58.33 %\n",
      "Cross-Validation in progress: 60.00 %\n",
      "Cross-Validation in progress: 61.67 %\n",
      "Cross-Validation in progress: 63.33 %\n",
      "Cross-Validation in progress: 65.00 %\n",
      "Cross-Validation in progress: 66.67 %\n",
      "Cross-Validation in progress: 68.33 %\n",
      "Cross-Validation in progress: 70.00 %\n",
      "Cross-Validation in progress: 71.67 %\n",
      "Cross-Validation in progress: 73.33 %\n",
      "Cross-Validation in progress: 75.00 %\n",
      "Cross-Validation in progress: 76.67 %\n",
      "Cross-Validation in progress: 78.33 %\n",
      "Cross-Validation in progress: 80.00 %\n",
      "Cross-Validation in progress: 81.67 %\n",
      "Cross-Validation in progress: 83.33 %\n",
      "Cross-Validation in progress: 85.00 %\n",
      "Cross-Validation in progress: 86.67 %\n",
      "Cross-Validation in progress: 88.33 %\n",
      "Cross-Validation in progress: 90.00 %\n",
      "Cross-Validation in progress: 91.67 %\n",
      "Cross-Validation in progress: 93.33 %\n",
      "Cross-Validation in progress: 95.00 %\n",
      "Cross-Validation in progress: 96.67 %\n",
      "Cross-Validation in progress: 98.33 %\n",
      "Cross-Validation is completed!\n",
      "\n",
      "The best model is: LinearDiscriminantAnalysis(priors=[0.5, 0.5])  with 20 features\n",
      "The accuracy of the best model is: 67.78%\n",
      "The roc_auc of the best model is: 58.36%\n",
      "The confusion matrix of the best model is:\n",
      " [[108  40]\n",
      " [ 18  14]]\n",
      "Test confusion matrix:\n",
      " [[451 299]\n",
      " [ 56  94]]\n"
     ]
    }
   ],
   "source": [
    "p8 = Person(data8)\n",
    "p8.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading the test data is started...\n",
      "Creating all possible features...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p8.load_test_data(data8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones founded: 1560\n",
      "Row-Column Display.\n",
      "The final word is:\n",
      " 3RV4D\n"
     ]
    }
   ],
   "source": [
    "p8.find_test_word()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Person 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating all possible features...\n",
      "\n",
      "\n",
      "Finding the best model is started...\n",
      "Cross-Validation in progress: 0.00 %\n",
      "Cross-Validation in progress: 1.67 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-d3fd1197718e>:210: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fisher_score = np.divide((n1 * (u1 - u0)**2 + n2 * (u2 - u0)**2),(n1*var1 + n2*var2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation in progress: 3.33 %\n",
      "Cross-Validation in progress: 5.00 %\n",
      "Cross-Validation in progress: 6.67 %\n",
      "Cross-Validation in progress: 8.33 %\n",
      "Cross-Validation in progress: 10.00 %\n",
      "Cross-Validation in progress: 11.67 %\n",
      "Cross-Validation in progress: 13.33 %\n",
      "Cross-Validation in progress: 15.00 %\n",
      "Cross-Validation in progress: 16.67 %\n",
      "Cross-Validation in progress: 18.33 %\n",
      "Cross-Validation in progress: 20.00 %\n",
      "Cross-Validation in progress: 21.67 %\n",
      "Cross-Validation in progress: 23.33 %\n",
      "Cross-Validation in progress: 25.00 %\n",
      "Cross-Validation in progress: 26.67 %\n",
      "Cross-Validation in progress: 28.33 %\n",
      "Cross-Validation in progress: 30.00 %\n",
      "Cross-Validation in progress: 31.67 %\n",
      "Cross-Validation in progress: 33.33 %\n",
      "Cross-Validation in progress: 35.00 %\n",
      "Cross-Validation in progress: 36.67 %\n",
      "Cross-Validation in progress: 38.33 %\n",
      "Cross-Validation in progress: 40.00 %\n",
      "Cross-Validation in progress: 41.67 %\n",
      "Cross-Validation in progress: 43.33 %\n",
      "Cross-Validation in progress: 45.00 %\n",
      "Cross-Validation in progress: 46.67 %\n",
      "Cross-Validation in progress: 48.33 %\n",
      "Cross-Validation in progress: 50.00 %\n",
      "Cross-Validation in progress: 51.67 %\n",
      "Cross-Validation in progress: 53.33 %\n",
      "Cross-Validation in progress: 55.00 %\n",
      "Cross-Validation in progress: 56.67 %\n",
      "Cross-Validation in progress: 58.33 %\n",
      "Cross-Validation in progress: 60.00 %\n",
      "Cross-Validation in progress: 61.67 %\n",
      "Cross-Validation in progress: 63.33 %\n",
      "Cross-Validation in progress: 65.00 %\n",
      "Cross-Validation in progress: 66.67 %\n",
      "Cross-Validation in progress: 68.33 %\n",
      "Cross-Validation in progress: 70.00 %\n",
      "Cross-Validation in progress: 71.67 %\n",
      "Cross-Validation in progress: 73.33 %\n",
      "Cross-Validation in progress: 75.00 %\n",
      "Cross-Validation in progress: 76.67 %\n",
      "Cross-Validation in progress: 78.33 %\n",
      "Cross-Validation in progress: 80.00 %\n",
      "Cross-Validation in progress: 81.67 %\n",
      "Cross-Validation in progress: 83.33 %\n",
      "Cross-Validation in progress: 85.00 %\n",
      "Cross-Validation in progress: 86.67 %\n",
      "Cross-Validation in progress: 88.33 %\n",
      "Cross-Validation in progress: 90.00 %\n",
      "Cross-Validation in progress: 91.67 %\n",
      "Cross-Validation in progress: 93.33 %\n",
      "Cross-Validation in progress: 95.00 %\n",
      "Cross-Validation in progress: 96.67 %\n",
      "Cross-Validation in progress: 98.33 %\n",
      "Cross-Validation is completed!\n",
      "\n",
      "The best model is: LinearDiscriminantAnalysis(priors=[0.5, 0.5])  with 40 features\n",
      "The accuracy of the best model is: 66.11%\n",
      "The roc_auc of the best model is: 52.96%\n",
      "The confusion matrix of the best model is:\n",
      " [[108  37]\n",
      " [ 24  11]]\n",
      "Test confusion matrix:\n",
      " [[483 267]\n",
      " [ 52  98]]\n"
     ]
    }
   ],
   "source": [
    "p9 = Person(data9)\n",
    "p9.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading the test data is started...\n",
      "Creating all possible features...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p9.load_test_data(data9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones founded: 1435\n",
      "Row-Column Display.\n",
      "The final word is:\n",
      " 5PZAN\n"
     ]
    }
   ],
   "source": [
    "p9.find_test_word()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
